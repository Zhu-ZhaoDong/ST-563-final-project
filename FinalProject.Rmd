---
title: "ST 563 Final Project"
author: ' '
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
---


## Introduction

We may guess the background of a newly met friend by their actions and talking to find a comfortable topic that won’t offend either of you. Similar things can apply to songs as well: the release year of most songs may have some time-specific “signatures” that are jointly determined by rhythm, dynamics, etc.

## Explaratory Data Analysis

```{r}
library(keras)
library(tensorflow)
library(rsample)
library (dplyr)
library(corrplot)
library(dplyr)
library (tfruns)
library(xgboost)
library (glmnet)
library(caret)
```

Reading the data
```{r}
train = read.delim(file = "data/YearPredictTrain.txt", header = TRUE, sep = ",", dec = ".")
test = read.delim(file = "data/YearPredictTest.txt", header = TRUE, sep = ",", dec = ".")
```


## Explanatory data analysis 

Correlation between covariates

```{r fig.height = 4, fig.width = 4}
corrplot(cor(select (train, -c (Year, Class))), method = "circle", tl.pos='n')
```

Correlation between covariates and response variable `Year`

```{r}
as.data.frame(cor(select(train, -c (Class))))$Year
```


Levels of response variable `Class`
```{r}
#train$Class = factor(train$Class)
levels(factor(train$Class))
```


Distribution for response variable - `Class`
```{r}
#dplyr::count(train, Class)
barplot(table (train$Class),  main="Class Distribution", 
   xlab="Number of observations per each class")
```

Check for NA values
```{r}
sum(is.na(train))
```

PCA analysis

```{r}
pc = prcomp(select (train, -c (Year, Class)),
            center = TRUE,
            scale. = TRUE)
summary(pc)
```

## Data Pre-processing

Scaling train and test datasets.

```{r}
set.seed(4)

x = model.matrix (Year ~.-1, data = select(train, -c(Class))) %>%
  scale()
y  = as.matrix (select(train, c(Year)))

x_test = model.matrix (Year ~.-1, data = select(test, -c(Class))) %>%
  scale()
y_test = as.matrix (select(test, c(Year)))
```


## Model Building - NN Regression


```{r}


train_flags = list (
dropout1 = c(0.2, 0.3, 0.4),
dropout2 = c(0.2, 0.3, 0.4),
nodes1 =   c(64, 128, 256),
nodes2 =   c(64, 128),
nodes3 =   c(32, 64, 128),
l2 = c(0.001, 0.05, 0.1),
optimizer =  c("rmsprop", "adam", "sgd"),
lr = c (0.01, 0.1, 0.5),
batch_size = c (100, 500),
epochs = c (100, 200)
)

#  train_flags =list (
#    dropout1 = c(0.4),
#    dropout2 = c(0.3),
#    nodes1 =   c(256),
#    nodes2 =   c(128),
#    nodes3 =   c(64),
#    l2 = c(0.01),
#    optimizer =  c("rmsprop"),
#    lr = c(0.1), 
#    batch_size = c (500),
#    epochs = c (100)
# )

set.seed (10)
runs_reg = tuning_run("nn_regression.R",  runs_dir = "runs_reg",
                  flags = train_flags,
                  sample = 0.01)
```


```{r}

best_run = ls_runs(order = metric_mean_squared_error, decreasing= F, runs_dir = 'runs_reg')[1,]
nn = keras_model_sequential() %>%
  layer_dense (unit = best_run$flag_nodes1, activation = "relu", 
               input_shape = ncol(x), 
               kernel_regularizer = regularizer_l2(l = best_run$l2)) %>%
   
  layer_dense (unit = best_run$flag_nodes2, activation = "relu") %>%
  layer_dropout(rate = best_run$flag_dropout1) %>%
  layer_dense (unit = best_run$flag_nodes3, activation = "relu") %>%
  layer_dense (units = 1)

nn %>% compile (loss = "mean_squared_error", 
                optimizer = optimizer_rmsprop(),
                metrics = list ("mean_squared_error", "mean_absolute_error"))

early_stop = callback_early_stopping(monitor = "val_loss", patience = 5)

history = nn %>% fit (x, y, epochs = best_run$flag_epochs, 
                      batch_size = best_run$flag_batch_size,
                      validation_split = 0.2,
                      verbose = 0, callbacks = list(early_stop, callback_reduce_lr_on_plateau(factor = best_run$flag_lr)))
plot (history)

score = nn %>% evaluate(
  x_test, y_test,
  verbose = 0
)
score

```


## Model Building - NN classification

```{r}
x = model.matrix (Class ~.-1, data = select(train, -c(Year))) %>%
  scale()
x_test = model.matrix (Class ~.-1, data = select(test, -c(Year))) %>%
  scale()

train$Class[train$Class == "prior to 1980"] = 0
train$Class[train$Class == "between 1980 - 2000"] = 1
train$Class[train$Class == "after 2000"] = 2
y_train_label = as.integer(train$Class)

test$Class[test$Class == "prior to 1980"] = 0
test$Class[test$Class == "between 1980 - 2000"] = 1
test$Class[test$Class == "after 2000"] = 2
y_test_label = as.integer(test$Class)

train_labels = y_train_label %>%
  to_categorical(3)
test_labels = y_test_label %>%
  to_categorical(3)
```


```{r}
 train_flags <-list (
    dropout1 = c(0.2, 0.3, 0.4),
    nodes1 =   c(32, 64, 128),
    nodes2 =   c(32, 64, 128),
    nodes3 =   c(32, 64, 128),
    l2 = c(0.001, 0.01, 0.05),
    lr = c(0.01, 0.1, 0.5),
    optimizer =  c("rmsprop", "adam", "sgd"),
    batch_size = c (100, 200),
    epochs = c (100, 200)
 )


 # train_flags <-list (
 #   dropout1 = c(0.3),
 #   nodes1 =   c(128),
 #   nodes2 =   c(128),
 #   nodes3 =   c(64),
 #   l2 = c(0.01),
 #   lr = c(0.1, 0.2),
 #   optimizer =  c("rmsprop"),
 #   batch_size = c (1000),
 #   epochs = c (200)
 # )


runs = tuning_run("nn_classification.R",  runs_dir = "runs",
                  flags = train_flags, 
                  sample = 0.01)
                  
best_run = ls_runs(order = metric_accuracy, decreasing= T, runs_dir = 'runs')[1,]


nn_cl = keras_model_sequential() %>%
  layer_dense (unit = best_run$flag_nodes1, activation = "relu", 
               input_shape = ncol(x), 
               kernel_regularizer = regularizer_l2(l = best_run$l2)) %>%
   
  layer_dense (unit = best_run$flag_nodes2, activation = "relu") %>%
  layer_dropout(rate = best_run$flag_dropout1) %>%
  layer_dense (unit = best_run$flag_nodes3, activation = "relu") %>%
  layer_dense (units = 3, activation = "softmax")


nn_cl %>% compile (loss = "categorical_crossentropy", 
                optimizer = optimizer_rmsprop(),
                metrics = list ("accuracy"))

early_stop = callback_early_stopping(monitor = "val_loss", patience = 5)

history = nn_cl %>% fit (x, train_labels, epochs =  best_run$flag_epochs, 
                      batch_size = best_run$flag_batch_size,
                      validation_split = 0.2,
                      verbose = 0, 
                      callbacks = list(early_stop, callback_reduce_lr_on_plateau(factor = best_run$flag_lr)))
plot (history)

score_cl = nn_cl %>% evaluate(
  x_test, test_labels,
  verbose = 0
)
score_cl

```


## Lasso regression

```{r}
set.seed(12)

grid = 10^seq (-3, 7, length = 100)
cv_out = cv.glmnet(x = x, y = y, alpha = 1, lambda = grid)
plot (cv_out)
```


```{r}
lasso_predictions = predict(cv_out$glmnet.fit, newx=x_test, s = cv_out$lambda.min)
mse_lasso=mean((y_test-lasso_predictions)^2)
mse_lasso
```


## XGBoost Regression
```{r}
train_control = trainControl(method = "cv", 
                             number = 5, 
                             search = "grid",
                             seeds = set.seed(50))

train_xgb = cbind(x, y)
gbmGrid <-  expand.grid(#max_depth = c(5, 7, 9), 
                        max_depth = c( 9),
                        #nrounds = (1:10)*50,
                        nrounds = c(100),  #, 200, 300),
                        eta = c (0.1),# 0.3, 0.5),
                        #gamma = c(0, 0.01, 0.1, 0.2),
                        gamma = c(0.1), #, 0.1),
                        subsample = c (0.8), # 0.8, 1),
                        min_child_weight = c (3), 
                        #min_child_weight = c(1, 3, 5),
                        colsample_bytree = 0.8)



set.seed (50)
model = caret::train(Year ~ . , 
                     data = train_xgb, 
                     method = "xgbTree", 
                     trControl = train_control, 
                     tuneGrid = gbmGrid,
                     verbosity = 0)

```

```{r}
model$bestTune
```


```{r}
pred_xgboost_reg <- predict(model,x_test)
pred_xgboost_reg_MSE <- (caret::RMSE(pred_xgboost_reg, y_test))^2
pred_xgboost_reg_MSE
```

## XGBoost Classification

```{r}
train_control = trainControl(method = "cv", 
                             number = 5, 
                             search = "grid",
                             #classProbs=TRUE,
                             summaryFunction = multiClassSummary,
                             seeds = set.seed(50))

train_xgb_cl = select (train, -c ( Year))
train_xgb_cl$Class = as.factor(train_xgb_cl$Class)
#levels(train_xgb_cl$Class) <- c("first_class", "second_class", "third_class")

gbmGrid <-  expand.grid(max_depth = c(3, 5, 7), 
                        nrounds = (1:10)*50,
                        eta = c (0.1, 0.3, 0.5),
                        gamma = 0,
                        subsample = 1,
                        min_child_weight = 1,
                        colsample_bytree = 0.8)


xgb_model_cl = caret::train( 
                             x  = select (train_xgb_cl, -c ("Class")),
                             y = train_xgb_cl$Class,
                             trControl = train_control,
                             method = "xgbTree",
                             tuneGrid = gbmGrid)


```




```{r}
test_xgb_cl = select (test, -c ( Year))
test_xgb_cl$Class = as.factor(test_xgb_cl$Class)
pred_xgboost_cl <- predict(xgb_model_cl, test_xgb_cl)
confusionMatrix (pred_xgboost_cl, test_xgb_cl$Class)
```
## Final Result
