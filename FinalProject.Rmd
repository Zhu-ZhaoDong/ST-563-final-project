---
title: "ST 563 Final Project"
author: ' '
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
---


## Introduction

We may guess the background of a newly met friend by their actions and talking to find a comfortable topic that won’t offend either of you. Similar things can apply to songs as well: the release year of most songs may have some time-specific “signatures” that are jointly determined by rhythm, dynamics, etc.

## Explaratory Data Analysis

```{r}
library(keras)
library(tensorflow)
library(rsample)
library (dplyr)
library(corrplot)
library(dplyr)
library (tfruns)
library(xgboost)
library (glmnet)
library(caret)
```

Reading the data
```{r}
train = read.delim(file = "data/YearPredictTrain.txt", header = TRUE, sep = ",", dec = ".")
test = read.delim(file = "data/YearPredictTest.txt", header = TRUE, sep = ",", dec = ".")
```

```{r fig.height = 4, fig.width = 4}
#head(train)
#summary (train)
#train$Class = factor(train$Class)
#levels(train$Class)
#corrplot(cor(select (train, -c (Year, Class))), method = "circle", tl.pos='n')
#pc = prcomp(select (train, -c (Year, Class)),
#            center = TRUE,
#            scale. = TRUE)
#summary(pc)
#sum(is.na(x ))
#sum(is.na(y_test))
```



## Data Pre-processing

Scaling train, test and validation datasets.

```{r}
set.seed(4)

x = model.matrix (Year ~.-1, data = select(train, -c(Class))) %>%
  scale()
y  = as.matrix (select(train, c(Year)))

x_test = model.matrix (Year ~.-1, data = select(test, -c(Class))) %>%
  scale()
y_test = as.matrix (select(test, c(Year)))
```


## Model Building - NN Regression


```{r}


train_flags <-list (
dropout1 = c(0.2, 0.3, 0.4),
dropout2 = c(0.2, 0.3, 0.4),
nodes1 =   c(64, 128, 256),
nodes2 =   c(32, 64, 128),
nodes3 =   c(32, 64, 128),
l2 = c(0.001, 0.05, 0.1),
optimizer =  c("rmsprop", "adam", "sgd"),
lr = c (0.01, 0.1, 0.5)
)

#  train_flags <-list (
#    dropout1 = c(0.4),
#    dropout2 = c(0.3),
#    nodes1 =   c(256),
#    nodes2 =   c(128),
#    nodes3 =   c(64),
#    l2 = c(0.1),
#    optimizer =  c("rmsprop"),
#    lr = c (0.1)
# )

set.seed (10)
runs_reg = tuning_run("nn_regression.R",  runs_dir = "runs_reg",
                  flags = train_flags,
                  sample = 0.05)
```


```{r}

best_run = ls_runs(order = metric_mean_squared_error, decreasing= F, runs_dir = 'runs_reg')[1,]
nn = keras_model_sequential() %>%
  layer_dense (unit = best_run$flag_nodes1, activation = "relu", 
               input_shape = ncol(x), 
               kernel_regularizer = regularizer_l2(l = best_run$l2)) %>%
   
  layer_dense (unit = best_run$flag_nodes2, activation = "relu") %>%
  layer_dropout(rate = best_run$flag_dropout1) %>%
  layer_dense (unit = best_run$flag_nodes3, activation = "relu") %>%
  layer_dense (units = 1)


#nn %>% compile (loss = "mean_squared_error", 
nn %>% compile (loss = "mse", 
                optimizer = optimizer_rmsprop(),
                metrics = list ("mean_squared_error", "mean_absolute_error"))

early_stop = callback_early_stopping(monitor = "val_loss", patience = 5)

history = nn %>% fit (x, y, epochs = 200, 
                      batch_size = 1000,
                      validation_split = 0.2,
                      verbose = 0, callbacks = list(early_stop, callback_reduce_lr_on_plateau(factor = best_run$flag_lr)))
plot (history)

score = nn %>% evaluate(
  x_test, y_test,
  verbose = 0
)
score


# pred <- predict(nn, x_test)
# MSE <- mean((y_test - pred)^2)
# abs_err <- mean(abs(y_test - pred))
# c(MSE = MSE, MAE = abs_err)
```


## Model Building - NN classification

```{r}
x = model.matrix (Class ~.-1, data = select(train, -c(Year))) %>%
  scale()

x_test = model.matrix (Class ~.-1, data = select(test, -c(Year))) %>%
  scale()

train$Class[train$Class == "prior to 1980"] = 0
train$Class[train$Class == "between 1980 - 2000"] = 1
train$Class[train$Class == "after 2000"] = 2
y_train_label = as.integer(train$Class)


test$Class[test$Class == "prior to 1980"] = 0
test$Class[test$Class == "between 1980 - 2000"] = 1
test$Class[test$Class == "after 2000"] = 2
y_test_label = as.integer(test$Class)


train_labels = y_train_label %>%
  to_categorical(3)

test_labels = y_test_label %>%
  to_categorical(3)
```

```{r}
 # train_flags <-list (
 #   dropout1 = c(0.2, 0.3, 0.4),
 #   nodes1 =   c(32, 64, 128),
 #   nodes2 =   c(32, 64, 128),
 #   nodes3 =   c(32, 64, 128),
 #   l2 = c(0.001, 0.01, 0.05),
 #   lr = c(0.01, 0.1, 0.5),
 #   optimizer =  c("rmsprop", "adam", "sgd") 
 # )


 train_flags <-list (
   dropout1 = c(0.3),
   nodes1 =   c(128),
   nodes2 =   c(128),
   nodes3 =   c(64),
   l2 = c(0.01),
   lr = c(0.1, 0.2),
   optimizer =  c("rmsprop") 
 )


runs = tuning_run("nn_classification.R",  runs_dir = "runs",
                  flags = train_flags, 
                  sample = 1)
                  
best_run = ls_runs(order = metric_accuracy, decreasing= T, runs_dir = 'runs')[1,]


nn_cl = keras_model_sequential() %>%
  layer_dense (unit = best_run$flag_nodes1, activation = "relu", 
               input_shape = ncol(x), 
               kernel_regularizer = regularizer_l2(l = best_run$l2)) %>%
   
  layer_dense (unit = best_run$flag_nodes2, activation = "relu") %>%
  layer_dropout(rate = best_run$flag_dropout1) %>%
  layer_dense (unit = best_run$flag_nodes3, activation = "relu") %>%
  layer_dense (units = 3, activation = "softmax")


nn_cl %>% compile (loss = "categorical_crossentropy", 
                optimizer = optimizer_rmsprop(),
                metrics = list ("accuracy"))

early_stop = callback_early_stopping(monitor = "val_loss", patience = 5)

history = nn_cl %>% fit (x, train_labels, epochs = 200, 
                      batch_size = 1000,
                      validation_split = 0.2,
                      verbose = 0, 
                      callbacks = list(early_stop, callback_reduce_lr_on_plateau(factor = best_run$flag_lr)))
plot (history)

score_cl = nn_cl %>% evaluate(
  x_test, test_labels,
  verbose = 0
)
score_cl

```


## Lasso regression

```{r}
set.seed(12)

grid = 10^seq (-3, 7, length = 100)
cv_out = cv.glmnet(x = x, y = y, alpha = 1, lambda = grid)
plot (cv_out)
```


```{r}
lasso_predictions = predict(cv_out$glmnet.fit, newx=x_test, s = cv_out$lambda.min)
mse_lasso=mean((y_test-lasso_predictions)^2)
mse_lasso
```


## XGBoost Regression
```{r}
train_control = trainControl(method = "cv", 
                             number = 5, 
                             search = "grid",
                             seeds = set.seed(50))

train_xgb = cbind(x, y)
gbmGrid <-  expand.grid(max_depth = c(3, 5, 7), 
                        nrounds = (1:10)*50,
                        eta = c (0.1, 0.3, 0.5),
                        gamma = 0,
                        subsample = 1,
                        min_child_weight = 1,
                        colsample_bytree = 0.8)



set.seed (50)
model = caret::train(Year ~ . , 
                     data = train_xgb, 
                     method = "xgbTree", 
                     trControl = train_control, 
                     tuneGrid = gbmGrid,
                     verbosity = 0)

```

```{r}
model$bestTune
```


```{r}
pred_xgboost_reg <- predict(model,x_test)
pred_xgboost_reg_MSE <- (caret::RMSE(pred_xgboost_reg, y_test))^2
pred_xgboost_reg_MSE
```

## XGBoost Classification

```{r}
train_control = trainControl(method = "cv", 
                             number = 5, 
                             search = "grid",
                             #classProbs=TRUE,
                             summaryFunction = multiClassSummary,
                             seeds = set.seed(50))

train_xgb_cl = select (train, -c ( Year))
train_xgb_cl$Class = as.factor(train_xgb_cl$Class)
#levels(train_xgb_cl$Class) <- c("first_class", "second_class", "third_class")

gbmGrid <-  expand.grid(max_depth = c(3, 5, 7), 
                        nrounds = (1:10)*50,
                        eta = c (0.1, 0.3, 0.5),
                        gamma = 0,
                        subsample = 1,
                        min_child_weight = 1,
                        colsample_bytree = 0.8)


xgb_model_cl = caret::train( 
                             x  = select (train_xgb_cl, -c ("Class")),
                             y = train_xgb_cl$Class,
                             trControl = train_control,
                             method = "xgbTree",
                             tuneGrid = gbmGrid)


```




```{r}
test_xgb_cl = select (test, -c ( Year))
test_xgb_cl$Class = as.factor(test_xgb_cl$Class)
pred_xgboost_cl <- predict(xgb_model_cl, test_xgb_cl)
confusionMatrix (pred_xgboost_cl, test_xgb_cl$Class)
```
## Final Result
